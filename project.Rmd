---
title: "project"
author: "Eric Friesth, Aashwin Lamsal"
date: "11/21/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Gun Violence incidences recorded in the US from 2013 to 2018

### Data Cleaning

```{r}
#Initial cleaning was done using MS Excel, we dropped columns that we weren't planning to use (Address, house district, senate district, part2-5_age) and removed rows with empty cells.
data = read.csv('gun-violence-202.csv')
head(data)
str(data)


#Changing data type for date from factor to date

data$date <- as.Date(data$date, format = "%m/%d/%Y")
#head(data)
#Date format is in YYYY-MM-DD

#Changing the data type for age from factor to int
data$part1_age <- as.integer(data$part1_age)
#head(data)
#str(data)

#Next, we drop rows with NA values using na.omit.

data_clean <- na.omit(data)
head(data_clean, 10)

# Finally, we noticed in our two factor variables, state and city_or_county, had levels "" (empty strings) that had to be removed as they were unwanted.

# We did this using the following code to drop levels.

data_clean$state[data_clean$state == ""] = NA
data_clean$state = droplevels(data_clean$state)
str(data_clean)

data_clean$city_or_county[data_clean$city_or_county == ""] = NA
data_clean$city_or_county = droplevels(data_clean$city_or_county)
str(data_clean)

# Extracted the year and month from the date to be used for more analysis

data_clean$year = substring(data_clean$date, 1, 4)

data_clean$month = substring(data_clean$date, 6, 7)

#changing the data types from characters to numeric

data_clean$year <- as.numeric(data_clean$year)
data_clean$month <- as.numeric(data_clean$month)

```

### Data Visualization

```{r}

library(tidyverse)
library(ggplot2)
library(ggmap)
library(sf)
library(mapview)
library(RColorBrewer)

#Creation of our continental US Map
map_bounds = c(left = -125, bottom = 25, right = -65, top = 50)

data_clean.map = get_stamenmap(map_bounds, zoom = 7, maptype = "toner-lite")

data_clean.map = ggmap(data_clean.map, extent = "device", legend = "none")

data_clean.map = data_clean.map + stat_density2d(data=data_clean, aes(x = data_clean$longitude, y = data_clean$latitude, fill = ..level.., alpha = ..level..), geom="polygon")

data_clean.map = data_clean.map + scale_fill_gradientn(colours = rev(brewer.pal(7, "Spectral")))


data_clean.map = data_clean.map + theme_bw()

# the code snippet below adds red points over each gun violence incident to the previous map
#data_clean.map <- data_clean.map + geom_point(data=data_clean,  aes(x=data_clean$longitude, y=data_clean$latitude), fill="red", shape=23, alpha=0.8)

ggsave(filename = "D:\\Documents\\ds202_project\\data_clean.png") #change this to something else for your own local directories


## Other Plots ( still need to order them )

# Scatter Pair plot:

pairs(data_clean[ ,7:18], pch = 19, lower.panel = NULL)


# Bar chart: state x sum(n_killed)
        # Can't get this reorder to work??

ggplot(data_clean, aes(x = reorder(state, -n_killed, function(x){sum(x) }), y = sum(n_killed))) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle=90, hjust=1)) + labs(x = "State", y= "Total Number Killed", title = "Total Killed Per State (2013-2018)")

# Bar chart: year x n_killed colored by state?

ggplot(data_clean, aes(x = year, y = n_killed, fill = state)) + geom_bar(stat = "identity", position = "fill")

ggplot(data_clean, aes(x = state, y = n_killed, fill = year)) + geom_bar(stat = "identity", position = "fill")


# Bar chart: state x age ?

ggplot(data_clean, aes(x = state, y = part1_age)) + geom_bar(stat = "identity") 


# Number of victims killed versus Number of Actors killed
ggplot(data_clean, aes(x = n_killed, y = n_part_killed)) + geom_histogram(stat="identity")
# Number of victims versus Number of Actors arrested
ggplot(data_clean, aes(x = n_killed, y = n_part_arrested)) + geom_histogram(stat="identity")

# Histogram: part1_age x sum(n_killed)

ggplot(data_clean, aes(x = part1_age, y = sum(n_killed), bins = 10)) + geom_histogram(stat = "identity", fill = "blue") + labs(x="Ages of Actors", y = "Total Number Killed", title = "Total Killed by Actors of Each Particular Age (2013-2018)")

 

# Histogram: year

ggplot(data_clean, aes(x = year)) + geom_histogram(stat = "count") + labs(x = "Year", y = "Frequency", title = "Distribution of Incidents by Year")


# Histogram: month

ggplot(data_clean, aes(x = month)) + geom_histogram(stat = "count", fill = "#42a14b") + labs(x = "Month", y = "Frequency", title = "Distribution of Incidents by Month") + ylim(0, 1200)


# Histogram: year x n_killed

ggplot(data_clean, aes(x = year, y = n_killed)) + geom_histogram(stat = "identity", fill = "#42a14b") + labs(x = "Month", y = "Frequency", title = "Distribution of Incidents by Month")


# Line graph: date x n_killed grouped by state?
# Time series??
# First we subset the dataframe, one for each year




# The grouping isn't ideal here, needs fixing



```



## Visualizations cont.

```{r}

ggplot(data_clean, aes(x = month, y = n_part_arrested)) + geom_bar(stat= "identity", fill = "#FB8B24") + labs(title = "Number of Actors Arrested by Month in the U.S.", x = "Month", y = "Number of Actors Arrested") + ylim(0, 650)
ggplot(data_clean, aes(x = month, y = n_part_killed)) + geom_bar(stat= "identity", fill = "#FB8B24") + labs(title = "Number of Actors Killed by Month in the U.S.", x = "Month", y = "Number of Actors Killed") + ylim(0, 650)


# Chicago
data_clean_chi = subset(data_clean, data_clean$city_or_county == "Chicago")

ggplot(data_clean_chi, aes(x = month, y = n_part_arrested)) + geom_bar(stat="identity", fill = "#05668D") + ylim(0, 25) + labs(title = "Number of Actors Arrested by Month in Chicago", x = "Month", y = "Number of Actors Arrested")

ggplot(data_clean_chi, aes(x = month, y = n_part_killed)) + geom_bar(stat="identity", fill = "#05668D") + ylim(0, 25) + labs(title = "Number of Actors Killed by Month in Chicago", x = "Month", y = "Number of Actors Killed")

ggplot(data_clean_chi, aes(x = month, y = n_killed)) + geom_bar(stat="identity", fill = "#05668D") + ylim(0, 25) + labs(title = "Number of People Killed by Month in Chicago", x = "Month", y = "Number of People Killed")


# New York (Bronx)
data_clean_nyc = subset(data_clean, data_clean$state == "New York")
data_clean_nyc = subset(data_clean, data_clean$city_or_county == "Bronx" | data_clean$city_or_county == "Brooklyn" | data_clean$city_or_county == "Staten Island" | data_clean$city_or_county == "Queens" | data_clean$city_or_county == "Manhattan")

ggplot(data_clean_nyc, aes(x = month, y = n_part_arrested)) + geom_bar(stat="identity", fill = "#E55934") + ylim(0, 25) + labs(title = "Number of Actors Arrested by Month in New York City", x = "Month", y = "Number of Actors Arrested")

ggplot(data_clean_nyc, aes(x = month, y = n_part_killed)) + geom_bar(stat="identity", fill = "#E55934") + ylim(0, 25) + labs(title = "Number of Actors Killed by Month in New York City", x = "Month", y = "Number of Actors Killed")

ggplot(data_clean_nyc, aes(x = month, y = n_killed)) + geom_bar(stat="identity", fill = "#E55934") + ylim(0, 25) + labs(title = "Number of People Killed by Month in New York City", x = "Month", y = "Number of People Killed")


# Des Moines
data_clean_dm = subset(data_clean, data_clean$city_or_county == "Des Moines")

ggplot(data_clean_dm, aes(x = month, y = n_part_arrested)) + geom_bar(stat="identity", fill = "#9BC53D") + ylim(0, 25) + labs(title = "Number of Actors Arrested by Month in Des Moines", x = "Month", y = "Number of Actors Arrested")

ggplot(data_clean_dm, aes(x = month, y = n_part_killed)) + geom_bar(stat="identity", fill = "#9BC53D") + ylim(0, 25) + labs(title = "Number of Actors Killed by Month in Des Moines", x = "Month", y = "Number of Actors Killed")

ggplot(data_clean_dm, aes(x = month, y = n_killed)) + geom_bar(stat="identity", fill = "#9BC53D") + ylim(0, 25) + labs(title = "Number of People Killed by Month in Des Moines", x = "Month", y = "Number of People Killed")


```

















## Predictive Models
### Teen actors in relation to the number killed/injured
```{r}
#Predictive Models below
#First, we look at Linear Models

#Looking for relationships between the number of teen actors and any of the other variables 
fit0 <- lm(n_teen_part~n_killed+n_injured,data=data_clean)
summary(fit0)
#Results show an Adjusted R-squared of 0.01936, an F-statistic of 107 with a p-value < 2.2e-16
#This can be interpreted that the estimate of the mean number of teen actors is 0.097279 when n_killed and n_injured are both 0.
#The 0.01 estimate for n_killed means that the mean value of teenage actors would be estimated to increase by 0.01 if n_killed increased by 1 unit, holding all other covariates constant.
#The 0.085432 estimate for n_injured means that the mean value of teenage actors would be estimated to increase by 0.085432 if n_injured increased by 1 unit, holding all other covariates constant.

#However, these results show that the number of people killed or injured are not good predictors for estimating the number of teenaged actors in gun violence, as it would be too difficult to predict something as unpredictable as gun violence.

```
### Number of people killed in relation to the different age groups of actors.
```{r}
#Looking for relationships between n_killed and the different age groups of participants 
fit1 = lm(n_killed~n_adult_part+n_teen_part+n_child_part, data=data_clean)
summary(fit1)





# UPDATE THIS COMMENT LATER:   Results to be interpreted in a similar manner as ABOVE

```
### The number of actors arrested, in relation to the age of the actor, disregarding children.
```{r}
fit2 = lm(n_part_arrested~n_adult_part+n_teen_part, data=data_clean)
summary(fit2)
#Results show an Adjusted R-squared of 0.1643, an F-statistic of 1056 with a p-value < 2.2e-16
#This can be interpreted that the estimate of the mean number of teen actors is -0.012580 when n_adult_part and n_teen_part are both 0. This means that 0.012580 of the average person is being unincarcerated when the number of teen and adult actors are both equal to 0. This doesn't make sense since you'd imagine the estimate to be 0 when the covariates are 0.
#The 0.330548 estimate for n_adult_part means that the mean value of actors arreseted would be estimated to increase by 0.330548 if n_adult_part increased by 1 unit, holding all other covariates constant.
#The 0.393224 estimate for n_teen_part means that the mean value of arrested actors would be estimated to increase by 0.393224 if n_teen_part increased by 1 unit, holding all other covariates constant.
#The correlation isn't strong enough to draw meaningful conclusions from this model, as the R squared is only 16%


```
### The number of actors killed vs the number of victims killed
```{r}
fit3 = lm(n_part_killed~n_adult_part+n_teen_part+n_killed, data=data_clean)
summary(fit3)

#Results show an Adjusted R-squared of 0.9963, an F-statistic of 9.562e+05 with a p-value < 2.2e-16
#This can be interpreted that the estimate of the mean number of actors who've died is 0.0011 when n_adult_part, n_teen_part, and n_killed are both 0 (though it's not 0, it's very close). This means that 0.0011 of the average actor is dead when the number of teen, adult actors, and number killed are all equal to 0. 
#The 0.0002468 estimate for n_adult_part means that the mean value of actors killed would be estimated to increase by 0.0002468 if n_adult_part increased by 1 unit, holding all other covariates constant.
#The -0.0009959 estimate for n_teen_part means that the mean value of dead actors would be estimated to increase by -0.0009959 if n_teen_part increased by 1 unit, holding all other covariates constant (this doesn't make much sense as the opposite of dying is coming back to life, which goes to show that these weren't good predictors).
# The 0.9925804 estimate for n_killed means taht the mean value of dead actors would increase by almost 1 when n_killed increases by 1 unit, holding all covariates constant.
#The correlation is strong enough, with an adjusted R-squared of 0.9963, but this dataset never clarified whether or not the actor gets added to this count whenever he/she dies. It seems like that might be the case due to the R-squared value being almost 1.


```




```{r}
#KNN Regression 

str(data_clean)


```

















